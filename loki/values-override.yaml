loki:
  enabled: true
  config:
    auth_enabled: false
    target: all
    chunk_store_config:
      max_look_back_period: 0s
    compactor:
      shared_store: filesystem
      working_directory: /data/loki/boltdb-shipper-compactor
    ingester:
      chunk_target_size: 524288
      chunk_block_size: 262144
      chunk_idle_period: 1m
      chunk_retain_period: 30s
      max_chunk_age: 10m
      lifecycler:
        ring:
          replication_factor: 1
      max_transfer_retries: 0
      wal:
        dir: /data/loki/wal
    limits_config:
      retention_period: 2400h
      enforce_metric_name: false
      max_entries_limit_per_query: 100000
      reject_old_samples: false
      reject_old_samples_max_age: 168h
      max_query_length: 0h
    memberlist:
      join_members:
      - loki-stack-memberlist
    schema_config:
      configs:
      - from: "2020-10-24"
        index:
          period: 24h
          prefix: index_
        object_store: filesystem
        schema: v11
        store: boltdb-shipper
    server:
      grpc_listen_port: 9095
      http_listen_port: 3100
    query_range:
      split_queries_by_interval: 0
      parallelise_shardable_queries: false
    querier:
      max_concurrent: 2048
    frontend:
      max_outstanding_per_tenant: 4096
      compress_responses: true
    storage_config:
      boltdb_shipper:
        active_index_directory: /data/loki/boltdb-shipper-active
        cache_location: /data/loki/boltdb-shipper-cache
        cache_ttl: 24h
        shared_store: filesystem
      filesystem:
        directory: /data/loki/chunks
    table_manager:
      retention_deletes_enabled: true
      retention_period: 720h  
  image:
    tag: 2.9.3
  service:
    type: NodePort

promtail:
  enabled: true
  extraArgs:
    - -config.expand-env=true
  config:
    clients:
      - url: http://{{ .Release.Name }}:3100/loki/api/v1/push
        drop_rate_limited_batches: true  # 429 에러(TooManyRequests) 발생 시 해당 배치를 더 이상 재시도하지 않고 바로 drop함.
        batchsize: 1048576    # 1MB (default)
        timeout: 3s
    server:
      queue_size: 1000        # 최대 큐 크기(=배치 실패시 1000개만 쌓이고 그 이상 drop)
    snippets:
      pipeline_stages: |-
        - drop:
            expression: '(.{65535,})'
        - cri: {}
        - regex:
            expression: '\[LOG_FOR_APP\]:(?P<json>\{.*\})'
        - json:
            expressions:
              uuid: uuid 
            source: json
        - labels:
            uuid:    
      common:
        - action: replace
          source_labels:
            - __meta_kubernetes_pod_node_name
          target_label: node_name  # Kubernetes 노드 이름을 기반으로 node_name 레이블을 생성합니다.
        - action: replace
          source_labels:
            - __meta_kubernetes_namespace
          target_label: namespace  # Pod의 네임스페이스를 기반으로 namespace 레이블을 생성합니다.
        - action: replace
          replacement: $1
          separator: /
          source_labels:
            - namespace
            - app
          target_label: job  # namespace와 app 레이블을 조합하여 job 레이블을 생성합니다.
        - action: replace
          source_labels:
            - __meta_kubernetes_pod_name
          target_label: pod  # Pod 이름을 기반으로 pod 레이블을 생성합니다.
        - action: replace
          source_labels:
            - __meta_kubernetes_pod_container_name
          target_label: container  # 컨테이너 이름을 기반으로 container 레이블을 생성합니다.
        - action: replace
          replacement: /var/log/pods/*$1/*.log
          separator: /
          source_labels:
            - __meta_kubernetes_pod_uid
            - __meta_kubernetes_pod_container_name
          target_label: __path__  # 로그 파일의 경로를 지정합니다.
        - action: replace
          replacement: /var/log/pods/*$1/*.log
          regex: true/(.*)
          separator: /
          source_labels:
            - __meta_kubernetes_pod_annotationpresent_kubernetes_io_config_hash
            - __meta_kubernetes_pod_annotation_kubernetes_io_config_hash
            - __meta_kubernetes_pod_container_name
          target_label: __path__    
      extraLimitsConfig: |-
        rate: 5000           # app별 초당 5000줄
        burst: 10000         # app별 순간 10000줄까지 허용
        drop: true           # 초과 시 drop (유실 허용)
        by_label_name: "app" # app label별로 독립 제한

      scrapeConfigs: |
        # Promtail의 스크레이프 구성 예시입니다. 참조: <https://github.com/grafana/loki/blob/master/production/ksonnet/promtail/scrape_config.libsonnet>
        - job_name: kubernetes-pods
          pipeline_stages:
            {{- toYaml .Values.config.snippets.pipelineStages | nindent 4 }}
          kubernetes_sd_configs:
            - role: pod  # Kubernetes 파드에서 로그를 수집합니다.
          relabel_configs:
            - source_labels:
                - __meta_kubernetes_pod_controller_name
              regex: ([0-9a-z-.]+?)(-[0-9a-f]{8,10})?
              action: replace
              target_label: __tmp_controller_name
            - source_labels:
                - __meta_kubernetes_pod_label_app_kubernetes_io_name
                - __meta_kubernetes_pod_label_app
                - __tmp_controller_name
                - __meta_kubernetes_pod_name
              regex: ^;*([^;]+)(;.*)?$
              action: replace
              target_label: app
            - source_labels:
                - __meta_kubernetes_pod_label_app_kubernetes_io_instance
                - __meta_kubernetes_pod_label_release
              regex: ^;*([^;]+)(;.*)?$
              action: replace
              target_label: instance
            - source_labels:
                - __meta_kubernetes_pod_label_app_kubernetes_io_component
                - __meta_kubernetes_pod_label_component
              regex: ^;*([^;]+)(;.*)?$
              action: replace
              target_label: component
            {{- if .Values.config.snippets.addScrapeJobLabel }}
            - replacement: kubernetes-pods
              target_label: scrape_job
            {{- end }}
            {{- toYaml .Values.config.snippets.common | nindent 4 }}
            {{- with .Values.config.snippets.extraRelabelConfigs }}
            {{- toYaml . | nindent 4 }}
            {{- end }}            

fluent-bit:
  enabled: false

grafana:
  enabled: true
  sidecar:
    datasources:
      label: grafana_datasource
      labelValue: "true"
      enabled: false
      maxLines: 1000
  image:
    tag: 10.3.3
  service:
    type: NodePort

prometheus:
  enabled: true
  isDefault: true
  url: http://{{ include "prometheus.fullname" .}}:{{ .Values.prometheus.server.service.servicePort }}{{ .Values.prometheus.server.prefixURL }}
# url: http://prometheus-server.monitoring.svc.cluster.local
  datasource:
    jsonData: "{}"
  server:
    service:
      type: NodePort
    extraArgs:
      enable-feature: remote-write-receiver
    extraScrapeConfigs: |
      - job_name: 'keda-operator-metrics-apiserver'
        scrape_interval: 10s
        static_configs:
          - targets:
              - keda-operator-metrics-apiserver.keda.svc.cluster.local:8080
      - job_name: 'kube-state-metrics'
        static_configs:
          - targets: ['loki-kube-state-metrics.logging.svc.cluster.local:8080']

filebeat:
  enabled: false

logstash:
  enabled: false